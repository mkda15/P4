\section{FFT}
This section describes the implementation of the FFT discussed in section \ref{sec:FFT}, which uses an implementation of the DFT discussed in section \ref{sec:DFT}. The implementation of the FFT is assessed by comparing both the computational efforts and the results of the implementations of the DFT and FFT compared to Numpy's FFT. The results are expected to be similar since the FFT is a fast way of calculating the DFT.

\subsection{Implementation of the FFT}
Firstly, the implementation of the DFT is described in the following algorithm.
\begin{algorithm}
\caption{DFT algorithm}
\label{DFTalg}
\begin{algorithmic}[1]
\Procedure{DFT}{x, c}
	\State{$X = np.zeros(c,dtype=complex)$}
	\For{k between 0 and length of signal}
		\State{$a = 0 + 0\cdot j$} \Comment{a is zero but of 			type complex}
		\For{n between 0 and c}
			\State{$a = \sum x[n]\cdot \exp(-2\cdot \pi\cdot j 					\cdot k \cdot n/float(c))$}
			\State{$X[k] = a$}
		\EndFor
	\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

The implementation of the FFT shown in the following algorithm uses a function to make sure that the number of samples to be computed is a power of 2 (as described in section \ref{sec:FFT}). This function asks if $N$ is positive and a power of 2. If not, the function returns a False-statement, which raises a \textit{Valueerror} in the FFT algorithm. However, the FFT function from the Numpy-package uses zeropadding to modify a signal of arbitrary length into a signal with a length that is a power of 2. That has not been implemented in the FFT shown below. In the FFT algorithm shown below, the signal is divided into even and odd samples if the signal is more than 2 samples long, which are computed separately by using the FFT itself; if the number of even (and odd) samples are still more than 2 the samples are divided even further until the number of even (and odd) samples are 2. These samples are then computed by the DFT described above. After dividing the samples into even and odd samples the twiddle factor is multiplied appropiately (as described in section \ref{sec:FFT}), and eventually the Numpy-function \textit{concatenate} is used to join the arrays back together \martin{Vi skal selvfølgelig lige undersøge, om algoritmen kan skrives pænere (specielt i bunden af FFT'en herunder)... \textregistered}.
\begin{algorithm}
\caption{FFT algorithm}
\label{FFTalg}
\begin{algorithmic}[1]
\State $N = $ \Comment{Number of samples to be computed}
\Procedure{Power of 2}{N}
	\State{Return $N != 0$ and $((N \& (N - 1)) == 0$}
\EndProcedure

\Procedure{FFT}{x}
	\State $N_{new}$ = length of signal x
	\If{Power of 2(N) == False:}
		\State{Raise Valueerror(``N should be a power of 2.'')}
	\ElsIf{$N_{new}$ == 2}
		\State{Return DFT(x,$N_{new}$)}
	\Else
		\State{$X_{even} = FFT(x[::2])$} \Comment{The even 				samples}
		\State{$X_{odd} = FFT(x[1::2])$} \Comment{The odd 				samples}
		\State{$factor = \exp(-2j\cdot \pi \cdot 						np.arange(N_{new}) / N_{new})$} \Comment{The twiddle 			factor}
		\State{Return $np.concatenate([X_{even} + factor[: 				N_{new} / 2] \cdot X_{odd}, X_{even} + factor[N_{new} / 		2:] \cdot X_{odd}])$}
	\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Validation of the FFT}
The FFT algorithm above is compared to both the DFT algorithm and the FFT function from the Numpy-package by measuring how long it takes for the functions to compute different amounts of random numbers and by comparing the outputs of the functions. This is shown in table \ref{tab:FTcompare}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Type / $N$ & DFT	   & FFT 	 & Numpy's FFT \\ \hline
$2^9$  	   & $1.03$    & $0.01$  & $\sim 0.00$ \\ \hline
$2^{10}$   & $4.43$    & $0.02$  & $\sim 0.00$ \\ \hline
$2^{11}$   & $17.36$   & $0.03$  & $\sim 0.00$ \\ \hline
$2^{12}$   & $69.42$   & $0.07$  & $\sim 0.00$ \\ \hline
$2^{13}$   & $290.89$  & $0.18$  & $\sim 0.00$ \\ \hline
$2^{14}$   & $1206.85$ & $0.27$  & $\sim 0.00$ \\ \hline
\end{tabular}
\caption{Times in seconds it take for the implementations of the DFT, the FFT and Numpy's FFT to compute $N$ random numbers.}
\label{tab:FTcompare}
\end{table}

Table \ref{tab:FTcompare} shows that the time the DFT takes to compute the $N$ numbers grows rapidly, whereas either of the FFTs take less than a second. The values for Numpy's FFT are rounded off to zero, and this functions ability to rapidly perform the computations is due to the fact that Numpy actually performs the computations in C, where the code is already compiled and run directly on the CPU. On the other hand, Python is an object-oriented language, which means that each line of the code has to be translated before it can be run. However, that obviously does not mean that the implementation of the FFT shown above is slow, and it is certainly much faster than the implementation of the DFT. \\
The implementation of the FFT and Numpy's FFT should also be compared for larger number of samples $N$ since e.g. $N = 2^{19}$ is 11.89 seconds with a sampling frequency of 44100 Hz, which is a reasonable length of an audio file from the recordings described in appendix \ref{recordings}. The DFT will obviously take too long and is therefore not included in the comparison in table \ref{tab:FT2compare}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Type / $N$ & FFT	   & Numpy's FFT \\ \hline
$2^{18}$   & $5.15$    & $0.03$ \\ \hline
$2^{19}$   & $9.79$    & $0.04$ \\ \hline
$2^{20}$   & $19.74$   & $0.14$ \\ \hline
$2^{21}$   & $40.31$   & $0.26$ \\ \hline
$2^{22}$   & $79.59$   & $0.56$ \\ \hline
$2^{23}$   & $159.39$  & $1.08$ \\ \hline
\end{tabular}
\caption{Times in seconds it take for the implementation of the FFT and Numpy's FFT to compute $N$ random numbers.}
\label{tab:FT2compare}
\end{table}

Obviously, the implementation of the FFT takes rather long for large numbers of samples, whereas Numpy's FFT only takes a little more than a second. It should be noted that the results above cannot be reproduced exactly since the numbers are random and the same amount of different numbers results in slightly different times of computations. Also, one might check the validity of the DFT and FFT algorithms by comparing the result of the algorithms and Numpy's FFT by using the Numpy function \textit{np.allclose}. An example is \textit{np.allclose(FFT(x),np.fft.fft(x)}, which returns a True-statement if the results of $FFT(x)$ described in algorithm \ref{FFTalg} and Numpy's FFT are similar to a certain degree$^[$\footnote{See also the documentation for the \textit{allclose}-function on \href{https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html}{https://docs.scipy.org}.}$^]$. This was always the case in the comparison of the implementations of the DFT, the FFT and Numpy's FFT described above.
\\ \\
Therefore, the implementation of the DFT and FFT described in algorithm \ref{DFTalg} and \ref{FFTalg}, respectively, returns the exact same values as Numpy's FFT. The DFT is obviously extremely slow for even rather small numbers of samples, and the FFT is also rather slow compared to Numpy's FFT for large numbers of samples.